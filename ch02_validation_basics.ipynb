{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab8b6d7-ad40-4da0-9511-e26478d84364",
   "metadata": {},
   "source": [
    "# Chapter #2: Validation Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc42875-1097-49f6-921c-857139711231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24637006-48d9-4ce4-a530-65ffd4990ae7",
   "metadata": {},
   "source": [
    "## 1. Creating train, test, and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb3470-b3c2-4019-a266-64634b3f2f61",
   "metadata": {},
   "source": [
    "1. Creating train, test, and validation datasets\n",
    "> Hello everyone - Let's get started with creating training, testing, and validation datasets.\n",
    "\n",
    "2. Traditional train/test split\n",
    "> In the first few lessons, we called data \"seen\" data if it was used for model fitting, while \"unseen\" data described the data we did not train our model on. In model validation, we use holdout samples to replicate this idea. We define a holdout dataset as any data that is not used for training and is only used to assess model performance. The available data is split into two datasets. One used for training, and one that is simply off limits while we are training our models, called a test (or holdout) dataset. This step is vital to model validation and is the number one step you can take to ensure your model's performance.\n",
    "\n",
    "3. Dataset definitions and ratios\n",
    "> We use the holdout sample as a testing dataset so that we can have an unbiased estimate for our model's performance after we are completely done training. Generally, a good rule of thumb is using an 80:20 split. This equates to setting aside twenty percent of the data for the test set and using the rest for training. You might choose to use more training data when the overall data is limited, or less training data if the modeling method is computationally expensive.\n",
    "\n",
    "4. The X and y datasets\n",
    "> Before we use scikit-learn's holdout creation function train_test_split(), we will use the tic_tac_toe dataset and create an X dataset with the predictive data, and a y dataset with just the responses. The first nine columns of tic_tac_toe can be used for training, while the 10th column contains the response values. As a quick aside, classification models for categorical values, such as those found in the tic_tac_toe dataset, require dummy variables. If you are unfamiliar with dummy variables, check out DataCamp's other courses that go into more detail here.\n",
    "\n",
    "5. Creating holdout samples\n",
    "> The train_test_split() function is straightforward. We split both the X and the y datasets, into both a train and a test dataset. This function has a few parameters that we will use. test_size takes either a float or an integer and specifies how big the test set should be. If test_size is blank, you can instead use train_size to set the size of the training set. And finally, random_state allows for setting the model seed and helps maintain reproducibility.\n",
    "\n",
    "6. Dataset for preliminary testing?\n",
    "> We know that the test set is off limits until we are completely done training, but what do we do when testing model parameters? For example, if we run a random forest model with 100 trees and one with 1000 trees, which dataset do we use to test these results?\n",
    "\n",
    "7. Holdout samples for parameter tuning\n",
    "> When testing parameters, tuning hyper-parameters, or anytime we are frequently evaluating model performance we need to create a second holdout sample, called the validation dataset. For this dataset, the available data is the original training dataset, which is then split in the same manner used to split the original complete dataset. We use the validation sample to assess our model's performance when using different parameter values.\n",
    "\n",
    "8. Train, validation, test continued\n",
    "> To create both holdout samples, the testing, and the validation datasets, we use scikit-learn's train_test_split() function twice. The first call will create training and testing datasets like normal. The second call we split this so-called temporary training dataset into the final training and validation datasets. In this example, we first used an 80/20 split to create the test set. With the 80% training dataset, we used a 75/25 split to create a validation dataset. Leaving us with 60% of the data for training, 20% for validation, and 20% for testing.\n",
    "\n",
    "9. It's holdout time\n",
    "> Let's practice making holdout sets to use in our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e0f156-27f8-4216-b0c0-3210e1afef04",
   "metadata": {},
   "source": [
    "### 1.1. Create one holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a8ed5-dd4f-49f4-91e7-c5259cdbe5bf",
   "metadata": {},
   "source": [
    "Your boss has asked you to create a simple random forest model on the `tic_tac_toe` dataset. She doesn't want you to spend much time selecting parameters; rather she wants to know how well the model will perform on future data. For future Tic-Tac-Toe games, it would be nice to know if your model can predict which player will win.\n",
    "\n",
    "The dataset tic_tac_toe has been loaded for your use.\n",
    "\n",
    "Note that in Python, =\\ indicates the code was too long for one line and has been split across two lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa10aad-bfb1-4bd7-805d-c689559e2d07",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363b05fe-40e7-40a6-a6c7-ab8b1c525a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "tic_tac_toe = pd.read_csv(\"./data/tic-tac-toe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb3c5dc-b93d-491a-809e-bdaf773c3664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "tic_tac_toe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1b220b-d88b-4e2b-a94d-cef9edea7e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a703dd4e-5260-43cb-8690-8ac09fb28cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column into (0 / 1):\n",
    "tic_tac_toe['Class'] = tic_tac_toe['Class'].apply(lambda x : 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f1672c-f1eb-4554-9331-7f961aa08c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the feaatures into (0 / 1):\n",
    "features = [col for col in tic_tac_toe.columns if col != 'Class']\n",
    "tic_tac_toe = pd.get_dummies(data=tic_tac_toe, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ed21481-2475-49e5-bacc-df8c46649460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to split the data into X & y:\n",
    "def split_data(data, y_col):\n",
    "    \n",
    "    features = [col for col in data.columns if col != y_col]\n",
    "    \n",
    "    X = data[features].copy()\n",
    "    y = data[y_col].copy()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97712b01-e0dc-464d-a52d-72dee0705c8c",
   "metadata": {},
   "source": [
    "- Create the `X` dataset by creating dummy variables for all of the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748a0c56-e1a6-431e-9690-1f18d85fdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slpitting the data into features matrix (X) & target column (y):\n",
    "X, y = split_data(tic_tac_toe, 'Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca5661-260e-4138-88d7-504b0892d3a6",
   "metadata": {},
   "source": [
    "- Split `X` and `y` into train (`X_train`, `y_train`) and test (`X_test`, `y_test`) datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48d5a2-6795-436f-bf97-5222daf6919d",
   "metadata": {},
   "source": [
    "- Split the datasets using 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3846f15a-aaa1-40cf-8bab-e5c9b28718a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training & hold-out sets:\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.1, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb7e1e-87fe-42f1-a2ca-f384581269e0",
   "metadata": {},
   "source": [
    "### 1.2. Create two holdout sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc9a11-86d7-4279-8bbb-945b93e1dca7",
   "metadata": {},
   "source": [
    "You recently created a simple random forest model to predict Tic-Tac-Toe game wins for your boss, and at her request, you did not do any parameter tuning. Unfortunately, the overall model accuracy was too low for her standards. This time around, she has asked you to focus on model performance.\n",
    "\n",
    "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset.\n",
    "\n",
    "The datasets `X` and `y` have been loaded for your use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddae540-ae52-4805-a711-9d482a3cbd1c",
   "metadata": {},
   "source": [
    "- Create temporary datasets and testing datasets (`X_test`, `y_test`). Use 20% of the overall data for the testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47220263-5a49-4cf8-8781-2f740c0a1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into temporary & hold-out sets:\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a390c6-d316-4569-9a38-759c87d7c726",
   "metadata": {},
   "source": [
    "- Using the temporary datasets (`X_temp`, `y_temp`), create training (`X_train`, `y_train`) and validation (`X_val`, `y_val`) datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34677301-a0bc-4fc6-bfbc-7852ce78aded",
   "metadata": {},
   "source": [
    "- Use 25% of the temporary data for the validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e18154f8-f3f7-44ba-902e-62efbf703df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the temporary dataset into training & validation sets:\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959c9a5-38bd-4df8-a2fa-58f8197aada4",
   "metadata": {},
   "source": [
    "### 1.3. Why use holdout sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914daa3-07a8-4119-836f-9fd4c9ae1799",
   "metadata": {},
   "source": [
    "It is important to understand when you would use three datasets (training, validation, and testing) instead of two (training and testing). There is no point in creating an additional dataset split if you are not going to use it.\n",
    "\n",
    "When should you consider using training, validation, and testing datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49076c44-5fc1-4340-90db-a1e353d7d07c",
   "metadata": {},
   "source": [
    "Possible Answers:\n",
    "- When there is a lot of data. Splitting into three sets helps speed up modeling.\n",
    "- When testing parameters, tuning hyper-parameters, or anytime you are frequently evaluating model performance.\n",
    "- Only when you are running regression and not classification models.\n",
    "- Only when you are running classification and not regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953b3f4-dc8f-4804-a5e6-01ec6c931fe6",
   "metadata": {},
   "source": [
    "> When testing parameters, tuning hyper-parameters, or anytime you are frequently evaluating model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904956db-049c-4fd7-abee-58226b43443e",
   "metadata": {},
   "source": [
    "## 2. Accuracy metrics: regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328eebdc-1d02-4e47-9914-99aa3875d613",
   "metadata": {},
   "source": [
    "1. Accuracy metrics: regression models\n",
    "> Now that we have learned about holdout samples let's discuss accuracy metrics used when validating models â€” starting with regression models.\n",
    "\n",
    "2. Regression models\n",
    "> Remember, regression models are built for continuous variables. This could be predicting the number of points a player will score tomorrow, or the number of puppies a dog is about to have!\n",
    "\n",
    "3. Mean absolute error (MAE)\n",
    "> To assess the performance of a regression model, we can use the mean absolute error. It is the simplest and most intuitive error metric and is the average absolute difference between the predictions (y_i) and the actual values (y_i hat). If your dog had six puppies, but you had predicted only four, the absolute difference would be two. This metric treats all points equally and is not sensitive to outliers. When dealing with applications where we don't want large errors to have a major impact, the mean absolute error can be used. An example could be predicting your car's monthly gas bill, when an outlier may have been caused by a one-time road trip.\n",
    "\n",
    "4. Mean squared error (MSE)\n",
    "> Next is the mean squared error (MSE). It is the most widely used regression error metric for regression models. It is calculated similarly to the mean absolute error, but this time we square the difference term. The MSE allows larger errors to have a larger impact on the model. Using the previous car example, if you knew once a year you might go on a road trip, you might expect to occasionally have a large error and would want your model to pick up on these trips.\n",
    "\n",
    "5. MAE vs. MSE\n",
    "> Picking between the MAE and the MSE comes down to the application. These results are in different units though and should not be directly compared!\n",
    "\n",
    "6. Mean absolute error\n",
    "> To practice these metrics, let's use the ultimate Halloween candy data dataset. Here we are predicting the win-percentage of candies in head-to-head match-ups with other candies. Let's assume we have already fit a random forest model and calculated predictions for the test dataset. For the mean absolute error, we can calculate this two ways. A manual calculation, which takes the sum of the absolute differences and divides by the total number of observations, or we can use scikit-learn's mean_absolute_error() function. We provide an array of the actual values, followed by an array of the predictions. Both methods produce a single value of 9-point-99 as the output. We are covering the manual calculations for these functions to understand the results of these error metrics. Notice that we are looking at the test data accuracy. This error means that we are about 10 percentage-points off on average when predicting the win-percentage. As win-percentages range from 0 to 1, this is fairly good.\n",
    "\n",
    "7. Mean squared error\n",
    "> For the mean squared error, we can calculate this manually or with the mean_squared_error() function. Both methods produce a value of 141-point-4. In this example, the mean squared error is a more appropriate accuracy metric, as we want outliers to have more of an impact on the model's performance. For example, if one chocolate bar really underperforms, there may be attributes of that chocolate bar that truly matter other than it being chocolate.\n",
    "\n",
    "8. Accuracy for a subset of data\n",
    "> Sometimes we want to know a model's accuracy for a specific subset, such as how this model performs on only chocolate candies. If column 1 in our test set has 1's for candies containing chocolate, and 0; otherwise, we filter the test array based on these values and run the accuracy metrics. Since the chocolate candies had errors of less than 9 and the non-chocolate candies had errors of 11, the model performed better on chocolate candy.\n",
    "\n",
    "9. Let's practice\n",
    "> Let's work through a couple of examples on regression accuracy metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618e93-0978-4fde-a390-37bd240b1190",
   "metadata": {},
   "source": [
    "### 2.1. Mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3a097-1b9d-4311-af00-7a7d72182555",
   "metadata": {},
   "source": [
    "Communicating modeling results can be difficult. However, most clients understand that on average, a predictive model was off by some number. This makes explaining the mean absolute error easy. For example, when predicting the number of wins for a basketball team, if you predict 42, and they end up with 40, you can easily explain that the error was two wins.\n",
    "\n",
    "In this exercise, you are interviewing for a new position and are provided with two arrays. `y_test`, the true number of wins for all 30 NBA teams in 2017 and `predictions`, which contains a prediction for each team. To test your understanding, you are asked to both manually calculate the MAE and use `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69651750-5019-409e-b108-44ad8a2ece4d",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18881aa5-1078-4b91-92b7-a165a17d44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying y_test & predictions from the workspace:\n",
    "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20,\n",
    "                   67, 61, 55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
    "\n",
    "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15,\n",
    "                        72, 58, 60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c2b6b-152d-4c5e-8b93-7f84d0859778",
   "metadata": {},
   "source": [
    "- Manually calculate the MAE using `n` as the number of observations predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3808957-a51d-4565-a929-af3ce87b9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean absolute error manually:\n",
    "mae_one = np.mean(abs(y_test - predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29716c-ee29-450e-9336-9290b9735f22",
   "metadata": {},
   "source": [
    "- Calculate the MAE using `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcb81bf1-b703-410f-b6ab-068c1da99c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean absolute error via sklearn's metric function:\n",
    "mae_two = mae(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54704169-020a-4ed3-bd18-c7251115df86",
   "metadata": {},
   "source": [
    "- Print off both accuracy values using the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1b22f0-63b9-49c4-a9f8-d6db963892b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 5.9\n",
      "Using scikit-learn, the error is 5.9\n"
     ]
    }
   ],
   "source": [
    "# Printing both:\n",
    "print(f'With a manual calculation, the error is {mae_one}')\n",
    "print(f'Using scikit-learn, the error is {mae_two}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa4ff5-aa5d-44bd-88aa-da2562a78d9f",
   "metadata": {},
   "source": [
    "### 2.2. Mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525cff8-12fc-4f5c-9439-0db2a283fe5a",
   "metadata": {},
   "source": [
    "Let's focus on the 2017 NBA predictions again. Every year, there are at least a couple of NBA teams that win way more games than expected. If you use the MAE, this accuracy metric does not reflect the bad predictions as much as if you use the MSE. Squaring the large errors from bad predictions will make the accuracy look worse.\n",
    "\n",
    "In this example, NBA executives want to better predict team wins. You will use the mean squared error to calculate the prediction error. The actual wins are loaded as `y_test` and the predictions as `predictions`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f2c61-4451-464d-9f67-dfc24fb07b59",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c470d3a-563f-463a-9bb2-7f9e90236bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying y_test & predictions from the workspace:\n",
    "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20,\n",
    "                   67, 61, 55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
    "\n",
    "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15,\n",
    "                        72, 58, 60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1bd47-5510-43ae-8550-d10790368578",
   "metadata": {},
   "source": [
    "- Manually calculate the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3ff322-94d0-4d53-ba92-a586068ee3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean squared error manually:\n",
    "mse_one = np.mean((y_test - predictions)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993980d7-f3b6-43a2-891a-41cda990936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a manual calculation, the error is 49.1\n"
     ]
    }
   ],
   "source": [
    "# Printing the result:\n",
    "print(f\"With a manual calculation, the error is {mse_one}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb90c3-57d8-4824-a0ea-8d23cc925467",
   "metadata": {},
   "source": [
    "- Calculate the MSE using `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41446849-7ab8-4649-bd19-104b9916d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean absolute error via sklearn's metric function:\n",
    "mse_two = mse(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ed1b295-8d81-4d02-993e-6dedb7673e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scikit-learn, the error is 49.1\n"
     ]
    }
   ],
   "source": [
    "# Printing the result:\n",
    "print(f\"Using scikit-learn, the error is {mse_two}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057ef73-f2b4-427f-b1fa-a5abf4b54e19",
   "metadata": {},
   "source": [
    "### 2.3. Performance on data subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c78d86-b0fe-4391-a259-a76c0da161fb",
   "metadata": {},
   "source": [
    "In professional basketball, there are two conferences, the East and the West. Coaches and fans often only care about how teams in their own conference will do this year.\n",
    "\n",
    "You have been working on an NBA prediction model and would like to determine if the predictions were better for the East or West conference. You added a third array to your data called `labels`, which contains an \"E\" for the East teams, and a \"W\" for the West. `y_test` and `predictions` have again been loaded for your use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fea5df-ba20-4947-86fe-bb942da457e4",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c61efe-dead-4c40-b118-1bdac5b8899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying labels from the workspace:\n",
    "labels = np.array(['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E',\n",
    "                   'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32517a-4d50-4529-abe4-ded0231fb8ca",
   "metadata": {},
   "source": [
    "- Create an array `east_teams` that can be used to filter `labels` to East conference teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a56ffde-5629-401c-956d-67103f391a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the east conference teams:\n",
    "east_teams = (labels == 'E')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af5aef4-5ecd-470d-8ebb-e7a56b18e64e",
   "metadata": {},
   "source": [
    "- Create the arrays `true_east` and `preds_east` by filtering the arrays `y_test` and `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a9a2beb-146d-4cba-8e94-c370a29baafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering true_east & preds_east arrays:\n",
    "true_east = y_test[east_teams]\n",
    "preds_east = predictions[east_teams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a51039-f816-4610-99bc-0bf6234fb64f",
   "metadata": {},
   "source": [
    "- Use the print statements to print the MAE (using `scikit-learn`) for the East conference. The `mean_absolute_error` function has been loaded as `mae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634e1d64-42a5-4728-9bbf-6735b0b3cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for East teams is 6.73\n"
     ]
    }
   ],
   "source": [
    "# Calculating & printing the mean absolute error:\n",
    "east_errors = mae(true_east, preds_east)\n",
    "print(f\"The MAE for East teams is {east_errors:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a6229-d38d-499e-baba-cd9e8ac61b65",
   "metadata": {},
   "source": [
    "- The variable `west_error` contains the MAE for the West teams. Use the print statement to print out the Western conference MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e42bfb5-f5c5-4e7e-b6bd-b491587b2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the west conference teams:\n",
    "west_teams = (labels == 'W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bd4ede3-b640-4f24-99b4-607e46812b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering true_west & preds_west arrays:\n",
    "true_west = y_test[west_teams]\n",
    "preds_west = predictions[west_teams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11ffc256-eda3-4d8e-9037-1ed426f0df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE for West conference is 5.07\n"
     ]
    }
   ],
   "source": [
    "# Calculating & printing the mean absolute error:\n",
    "west_errors = mae(true_west, preds_west)\n",
    "print(f\"The MAE for West conference is {west_errors:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c97734-e314-4676-bdf6-b3f9d8f1a50b",
   "metadata": {},
   "source": [
    "## 3. Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c061f-6bb3-4082-bf82-ecf55c4a4e3c",
   "metadata": {},
   "source": [
    "1. Classification metrics\n",
    "> Welcome back! We already understand classification models; now let's look at their accuracy metrics.\n",
    "\n",
    "2. Classification metrics\n",
    "> Classification accuracy metrics are quite a bit different than regression ones. Remember, with classification models; we are predicting what category an observation falls into. There are a lot of accuracy metrics available. There is precision, recall, accuracy, specificity, F1-Score, alternate forms of the F1-score, and several others.\n",
    "\n",
    "3. Classification metrics\n",
    "> We will focus on precision, recall, and accuracy. As each of these are easy to understand and have very practical applications. One way to calculate these metrics is to use the values from the confusion matrix.\n",
    "\n",
    "4. Confusion matrix\n",
    "> When making predictions, especially if there is a binary outcome, this matrix is one of the first outputs you should review. When we have a binary outcome, the confusion matrix is a 2x2 matrix that shows how your predictions faired across the two outcomes. For example, for predictions of 0 that were actually 0 (or true negatives), we look at the 0, 0 square of the matrix. All of the accuracy metrics from the previous slide can be calculated using the values from this matrix, and it is a great way to visualize the initial results of your classification model.\n",
    "\n",
    "5. Create confusion matrix with scikit-learn\n",
    "> We can create a confusion matrix using scikit-learn's function confusion_matrix(). When dealing with binary data, this will print out a 2x2 array which represents the confusion matrix. In this matrix, the row index represents the true category, and the column index represents the predicted category. Therefore, the 1, 0 entry of the array represents the number of true 1s that were predicted to be 0, or 8 in this example.\n",
    "\n",
    "6. Accuracy\n",
    "> Accuracy is the easiest metric to understand and represents the overall ability of your model to correctly predict the correct classification. Using the confusion matrix, we add the values that were predicted 0 and actually are 0 (which are called true negatives), to the values predicted to be 1 that are 1 (called true positives), and then divide by the total number of observations. In this case, our accuracy was 85%. In this example, you can associate a true positive as predicted 1's that are also actually 1's. However, if your categories were win or loss, you might associate a true positive as the number of predicted wins that were actually wins.\n",
    "\n",
    "7. Precision\n",
    "> Next is precision or the number of true positives out of all predicted positive values. We correctly predicted 62 true values but also predicted 7 false positives. Therefore, the precision is 62 divided by 69. Precision is used when we don't want to overpredict positive values. If it cost $2,000 to fly-in potential new employee's, a company may only have on-campus interviews with individuals that they really believe are going to join their company. In the example data, almost 9 out of 10 predicted 1's would have joined the company.\n",
    "\n",
    "8. Recall\n",
    "> The recall metric is about finding all positive values. Here we correctly predicted 62 true positives and had 8 false negatives. Our recall is 62 out of 70. Recall is used when we can't afford to miss any positive values. For example, even if a patient has a small chance of having cancer, we may want to give them additional tests. The cost of missing a patient who has cancer is far greater than the cost of additional screenings for that patient.\n",
    "\n",
    "9. Accuracy, precision, recall\n",
    "> Accuracy, precision, and recall are called similarly. Use the desired accuracy metric function and provide the true and predicted values. A single value will be produced as a result. In this example, we got the same values that we calculated using the confusion matrix.\n",
    "\n",
    "10. Practice time\n",
    "> Let's work through a couple of examples using these accuracy metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e204294-0b6c-4ef6-91d1-3b36ff654bb7",
   "metadata": {},
   "source": [
    "### 3.1. Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e78d1f-6ff3-44b5-8182-e2a7701fdf60",
   "metadata": {},
   "source": [
    "Confusion matrices are a great way to start exploring your model's accuracy. They provide the values needed to calculate a wide range of metrics, including sensitivity, specificity, and the F1-score.\n",
    "\n",
    "You have built a classification model to predict if a person has a broken arm based on an X-ray image. On the testing set, you have the following confusion matrix:"
   ]
  },
  {
   "attachments": {
    "4c6c1ee4-1407-4d2a-8762-82b668880f9e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "efb622da-8b7a-45c5-851b-348d052c2bbd",
   "metadata": {},
   "source": [
    "![image.png](attachment:4c6c1ee4-1407-4d2a-8762-82b668880f9e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dcc48-11f3-41a0-a35c-e5f17a42961f",
   "metadata": {},
   "source": [
    "- Use the confusion matrix to calculate overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "807fd9b9-72af-4e40-aa41-6da44b028a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning values:\n",
    "TP, TN, FP, FN = 491, 324, 15, 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07ea5c79-39de-49b9-b97e-66b9b50b9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy:\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f394bb-f0a9-4dc8-b5c1-b799f51e6c33",
   "metadata": {},
   "source": [
    "- Use the confusion matrix to calculate precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a292bd6c-56bf-495f-a029-776b14863dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision:\n",
    "precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44dc45cb-6730-42a6-97c1-9f65b1d312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating recall:\n",
    "recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b3f9d-a6ab-498a-8ecb-7f94d4979f14",
   "metadata": {},
   "source": [
    "- Use the three print statements to print each accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0975ee96-7ee7-4073-b1d7-f6390e0a8fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy is 0.86\n",
      "The precision is 0.97\n",
      "The recall is 0.80\n"
     ]
    }
   ],
   "source": [
    "# Printing accuracy, precision & recall:\n",
    "print(f\"The overall accuracy is {accuracy:.2f}\")\n",
    "print(f\"The precision is {precision:.2f}\")\n",
    "print(f\"The recall is {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdcd96-25f4-4271-8ba3-9809cce462d5",
   "metadata": {},
   "source": [
    "### 3.2. Confusion matrices, again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e39bf4-6e9c-47c4-9caf-ebdd05e7ac9e",
   "metadata": {},
   "source": [
    "Creating a confusion matrix in Python is simple. The biggest challenge will be making sure you understand the orientation of the matrix. This exercise makes sure you understand the `sklearn` implementation of confusion matrices. Here, you have created a random forest model using the `tic_tac_toe` dataset `rfc` to predict outcomes of 0 (loss) or 1 (a win) for Player One.\n",
    "\n",
    "Note: If you read about confusion matrices on another website or for another programming language, the values might be reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144694d-0bc9-4333-bb01-6be9374bcf83",
   "metadata": {},
   "source": [
    "- Geting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d00acf9-93ae-421c-8e3a-39fdf2b094b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "tic_tac_toe = pd.read_csv(\"./data/tic-tac-toe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670afbc8-8a39-4ce4-ab10-3ad3ba80fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "tic_tac_toe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72f9e7c1-f913-4592-9fba-01568b04bd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ec045c9-d0c3-43e3-983a-d96300341166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target column into (0 / 1):\n",
    "tic_tac_toe['Class'] = tic_tac_toe['Class'].apply(lambda x : 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1306642-d2cb-4871-96a7-cdb173daf96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the feaatures into (0 / 1):\n",
    "features = [col for col in tic_tac_toe.columns if col != 'Class']\n",
    "tic_tac_toe = pd.get_dummies(data=tic_tac_toe, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15f7fd1d-4cdb-4b2d-a1ec-eb213ab61e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slpitting the data into features matrix (X) & target column (y):\n",
    "X, y = split_data(tic_tac_toe, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e418cb-ede6-4abf-904b-f29d7bcd980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training & hold-out sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=863, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cadc25fc-fcbd-4ff6-95e8-3edefdf9765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the model params from datacamp workspace:\n",
    "params = {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini',\n",
    "          'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None,\n",
    "          'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1,\n",
    "          'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500,\n",
    "          'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccfada67-6d89-4788-a59d-6c8e133b6be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=1111)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing & fitting the model:\n",
    "rfc = RandomForestClassifier(**params)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c6cab-c3ad-4704-9e79-666236c022e9",
   "metadata": {},
   "source": [
    "- Import `sklearn`'s function for creating confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91332149-6bdf-434c-b78b-10450120d8ec",
   "metadata": {},
   "source": [
    "> Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0f621d-b9ae-4e4e-bb64-efa66aa5bb7e",
   "metadata": {},
   "source": [
    "- Using the model `rfc`, create category predictions on the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdcce9a8-09dd-442e-a389-5cdf5d297aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions necessary for model evaluation:\n",
    "test_predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dae8b29e-076c-4e24-9b45-76e06730201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[177, 123],\n",
       "       [ 92, 471]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the model confusion matrix:\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6b0cd2e-d243-4c36-9ec6-f5f1c81865b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of true positives is: 471\n"
     ]
    }
   ],
   "source": [
    "# Printing TPs:\n",
    "print(f\"The number of true positives is: {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa19a6f-5f91-4694-ac06-becba3170f8f",
   "metadata": {},
   "source": [
    "### 3.3. Precision vs. recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d8c87-d9ef-4835-93cc-f7697990285b",
   "metadata": {},
   "source": [
    "The accuracy metrics you use to evaluate your model should always be based on the specific application. For this example, let's assume you are a really sore loser when it comes to playing Tic-Tac-Toe, but only when you are certain that you are going to win.\n",
    "\n",
    "Choose the most appropriate accuracy metric, either precision or recall, to complete this example. But remember, if you think you are going to win, you better win!\n",
    "\n",
    "Use `rfc`, which is a random forest classification model built on the `tic_tac_toe` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54099042-ea0b-422e-9f11-a05f066747af",
   "metadata": {},
   "source": [
    "- Import the precision or the recall metric for sklearn. Only one method is correct for the given context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a617bd-d253-4a42-894c-1fb688c53355",
   "metadata": {},
   "source": [
    "> Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82450b-1e2e-4ce5-8728-baab36ad4237",
   "metadata": {},
   "source": [
    "- Calculate the precision or recall using y_test for the true values and test_predictions for the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d84470d-2c1a-47f9-8981-54254c02b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision:\n",
    "score = precision_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06f6c9-c222-4234-bacc-ed7730e00f1e",
   "metadata": {},
   "source": [
    "- Print the final score based on your selected metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cb976ba-d869-40c7-bcd1-0d4306246225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision value is 0.79\n"
     ]
    }
   ],
   "source": [
    "# Printing precision score:\n",
    "print(f\"The precision value is {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caebd88-c62c-4992-94b8-8ebaad99f6d0",
   "metadata": {},
   "source": [
    "## 4. The bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f136b6-3bd8-424b-a8b1-0effb6ac0dc5",
   "metadata": {},
   "source": [
    "1. The bias-variance tradeoff\n",
    "> Hello again. Let's try to identify when we have a good fitting model.\n",
    "\n",
    "2. Variance\n",
    "> One way to do this is to consider bias and variance. Variance occurs when a model pays too close attention to the training data and fails to generalize to the testing data. These models perform well on only the training data, but not the testing data, and are considered to be overfit.\n",
    "\n",
    "3. Overfitting models (high variance)\n",
    "> Overfitting occurs when our model starts to attach meaning to the noise in the training data. In this graphic, you can see the natural quadratic shape of the orange dots. However, our blue prediction line is hugging the data and would likely not extend well to new orange dots. Overfitting is easy to identify though, as the training error will be a lot lower than the testing error.\n",
    "\n",
    "4. Bias\n",
    "> The second term, Bias, occurs when the model fails to find the relationships between the data and the response value. Bias leads to high errors on both the training and testing datasets and is associated with an underfit model.\n",
    "\n",
    "5. Underfitting models (high bias)\n",
    "> Underfitting occurs when the model could not find the underlying patterns available in the data. This might happen if we don't have enough trees or the trees aren't deep enough. In this example, we have the average of the actual values acting as our prediction. Underfitting is more difficult to identify because the training and testing errors will both be high, and it's difficult to know if we got the most out of the data, or if we can improve the testing error.\n",
    "\n",
    "6. Optimal performance\n",
    "> When our model is getting the most out of the training data, while still performing on the testing data, we have optimal performance. Notice how the blue line is matching the natural quadratic shape of the data and that it is not touching every orange dot. The blue line is a well fit prediction line for future data. So how do we tell if we have a good fit, or if we are just underfitting?\n",
    "\n",
    "7. Parameters causing over/under fitting\n",
    "> For random forest models, some parameters that affect performance are max depth and max features. One way to check for a poorly fit model is to try additional parameter sets and check both the training and testing error metrics. Notice that the overall training accuracy is a bit higher than the testing accuracy. We might have some past experience with this type of data that suggests we can expect a much higher accuracy and we conclude that we are probably underfitting. As you run more random forest models, you will get a better sense of which parameters you should tweak. But in this case, a max depth of 4 is probably not deep enough.\n",
    "\n",
    "8. Parameters continued\n",
    "> This time around, we may have made the max depth too large and are overfitting. Achieving 100% accuracy on the training dataset while only getting 83% on testing is a clear sign that we are overfitting. We always compare how well the model performed on the data it has seen to the data it has not seen.\n",
    "\n",
    "9. Parameters continued\n",
    "> Finally, a max depth of 10 has brought the testing accuracy up, while also bringing it closer to the training accuracy. Indicating that the model is generalizing well to new data while still performing really well overall. We will never know if 86% is the best accuracy possible for this dataset. However, we have explored various parameter sets, checked the difference between the testing and training errors at each stage, and improved our accuracy by almost 10% over the first model that we created.\n",
    "\n",
    "10. Remember, only you can prevent overfitting!\n",
    "> We will explore parameter tuning later in this course. For now, let's see how changing a single parameter value affects model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44eb8e4-9b1b-4b7f-9d26-69bf5ffd9223",
   "metadata": {},
   "source": [
    "### 4.1. Error due to under/over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a035b5-3c29-4e13-be93-aa9e154eb801",
   "metadata": {},
   "source": [
    "The candy dataset is prime for overfitting. With only 85 observations, if you use 20% for the testing dataset, you are losing a lot of vital data that could be used for modeling. Imagine the scenario where most of the chocolate candies ended up in the training data and very few in the holdout sample. Our model might only see that chocolate is a vital factor, but fail to find that other attributes are also important. In this exercise, you'll explore how using too many features (columns) in a random forest model can lead to overfitting.\n",
    "\n",
    "A feature represents which columns of the data are used in a decision tree. The parameter `max_features` limits the number of features available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd769a4-4683-4a58-9bed-5f38f1bc4f07",
   "metadata": {},
   "source": [
    "- Getting everything ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5461d854-89a1-44ee-9485-404f20a54559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data:\n",
    "candy = pd.read_csv(\"./data/candy-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95293791-4b23-49fb-86a4-a4be7315c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the data shape:\n",
    "candy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20cf84c8-ffa9-49de-9ab8-11d3bbb47b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the first 5 rows:\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba02640-ce8c-4c5d-b4f6-32715133d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the first column:\n",
    "candy.drop(columns='competitorname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aef00655-748f-48aa-8695-969689b34786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into feature matrix (X) & target column (y):\n",
    "X, y = split_data(candy, 'winpercent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98829d11-53db-43d1-b911-d5ee25676da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training & hold-out sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=17, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea6e50-aecf-4818-914c-e55fd1c792e3",
   "metadata": {},
   "source": [
    "- Create a random forest model with 25 trees, a random state of 1111, and max_features of 2. Read the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b80b8c3-524b-4c62-bc68-a992bbe7a707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=2, n_estimators=25, random_state=1111)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing & fitting the model:\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=2)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ddfd371-d65c-424f-a1ff-56f337bb4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.90\n",
      "The testing error is 9.15\n"
     ]
    }
   ],
   "source": [
    "# Printing the training and testing accuracy scores: \n",
    "print(f\"The training error is {mae(y_train, rfr.predict(X_train)):.2f}\")\n",
    "print(f\"The testing error is {mae(y_test, rfr.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a37ceee-3496-49dc-ba51-9edc1c7873fb",
   "metadata": {},
   "source": [
    "- Set max_features to 11 (the number of columns in the dataset). Read the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d05405c2-4bd5-4e56-b695-25dee572cd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=11, n_estimators=25, random_state=1111)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing & fitting the model:\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=11)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0f0b079-e20f-48fe-b3c9-0be7708c2170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.59\n",
      "The testing error is 10.00\n"
     ]
    }
   ],
   "source": [
    "# Printing the training and testing accuracy scores: \n",
    "print(f\"The training error is {mae(y_train, rfr.predict(X_train)):.2f}\")\n",
    "print(f\"The testing error is {mae(y_test, rfr.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b45258-aaa6-4dca-b9fe-10c14704fc10",
   "metadata": {},
   "source": [
    "- Set max_features equal to 4. Read the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fb48877-6662-4392-a181-36c0ff5a7d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=4, n_estimators=25, random_state=1111)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing & fitting the model:\n",
    "rfr = RandomForestRegressor(n_estimators=25, random_state=1111, max_features=4)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37a8f841-6617-4aa8-90b6-8ebd2632db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is 3.60\n",
      "The testing error is 8.79\n"
     ]
    }
   ],
   "source": [
    "# Printing the training and testing accuracy scores: \n",
    "print(f\"The training error is {mae(y_train, rfr.predict(X_train)):.2f}\")\n",
    "print(f\"The testing error is {mae(y_test, rfr.predict(X_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b66cd-317e-4812-a9e6-59cbea526ccb",
   "metadata": {},
   "source": [
    "### 4.2. Am I underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3d4da-f9f2-4180-9913-8177c934ff9f",
   "metadata": {},
   "source": [
    "You are creating a random forest model to predict if you will win a future game of Tic-Tac-Toe. Using the `tic_tac_toe` dataset, you have created training and testing datasets, `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "\n",
    "You have decided to create a bunch of random forest models with varying amounts of trees (1, 2, 3, 4, 5, 10, 20, and 50). The more trees you use, the longer your random forest model will take to run. However, if you don't use enough trees, you risk underfitting. You have created a for loop to test your model at the different number of trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e14a53-52af-46e3-947f-7043f3af5838",
   "metadata": {},
   "source": [
    "- For each loop, predict values for both the X_train and X_test datasets.\n",
    "- For each loop, append the accuracy_score() of the y_train dataset and the corresponding predictions to train_scores.\n",
    "- For each loop, append the accuracy_score() of the y_test dataset and the corresponding predictions to test_scores.\n",
    "- Print the training and testing scores using the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c280f88-d54a-4081-b009-f0f058c5fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slpitting the data into features matrix (X) & target column (y):\n",
    "X, y = split_data(tic_tac_toe, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52d003ba-5122-4c3b-8972-220e34821db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training & hold-out sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=192, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b76d58e-f81b-444e-b644-8f51e7b920c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training scores were: [0.94, 0.93, 0.98, 0.97, 0.99, 1.0, 1.0, 1.0]\n",
      "The testing scores were: [0.83, 0.79, 0.89, 0.91, 0.91, 0.93, 0.97, 0.98]\n"
     ]
    }
   ],
   "source": [
    "# Printing the train & test scores for each run:\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions for X_train and X_test datasets.\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    test_predictions = rfc.predict(X_test)\n",
    "    \n",
    "    # Appending the accuracy score for test and train predictions.\n",
    "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
    "    \n",
    "# Printing the train and test scores:\n",
    "print(f\"The training scores were: {train_scores}\")\n",
    "print(f\"The testing scores were: {test_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
